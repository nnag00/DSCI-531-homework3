{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38cb824b",
   "metadata": {},
   "source": [
    "# HW3 - Measuring Gender Bias in Pretrained Language Model on Named Entity Recognition - DSCI 531 - Spring 2023\n",
    "\n",
    "### Please complete the code or analysis under “TODO”. 100pts in total. You should run every cell and keep all the outputs before submitting. Failing to include your outputs will result in zero points.\n",
    "\n",
    "### Please keep in mind the academic integrity. Plagiarism will be taken seriously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2f157c-4411-43ba-831d-84d223050d3a",
   "metadata": {},
   "source": [
    "## Name: Nandini Nag\n",
    "\n",
    "## USC ID: 8309782868"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf4971f",
   "metadata": {},
   "source": [
    "## Example of using a finetuned BERT on NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "683c9413-e214-4d21-849f-535000ee68d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/anaconda3/lib/python3.12/site-packages (4.49.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f102b57f-ac60-478c-ad35-8feb362eae69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.12/site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in /opt/anaconda3/lib/python3.12/site-packages (0.21.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/anaconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "665a3046-5565-4dcb-a494-0cfa8bbcee5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ba549d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2507005b8464cd8a4219ffa4a61aae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dslim/bert-base-NER were not used when initializing BertForTokenClassification: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline\n",
    "\n",
    "# a finetuned BERT model for NER on CoLL-2003 Named Entity Recognition\n",
    "# https://huggingface.co/dslim/bert-base-NER\n",
    "model_name = 'dslim/bert-base-NER'\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
    "\n",
    "nlp = pipeline(\n",
    "    \"ner\", model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    device=0   # the gpu id to use. If no gpu available, set it to -1. Setting it to 0/1/2/3... indicates using the corresponding gpu\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d73d85a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'entity': 'B-PER',\n",
       "   'score': 0.999311,\n",
       "   'index': 1,\n",
       "   'word': 'Wolfgang',\n",
       "   'start': 0,\n",
       "   'end': 8},\n",
       "  {'entity': 'B-LOC',\n",
       "   'score': 0.9995962,\n",
       "   'index': 4,\n",
       "   'word': 'Berlin',\n",
       "   'start': 18,\n",
       "   'end': 24}],\n",
       " [],\n",
       " [{'entity': 'B-PER',\n",
       "   'score': 0.99702424,\n",
       "   'index': 1,\n",
       "   'word': 'Elizabeth',\n",
       "   'start': 0,\n",
       "   'end': 9}],\n",
       " [{'entity': 'B-LOC',\n",
       "   'score': 0.9993932,\n",
       "   'index': 1,\n",
       "   'word': 'Tennessee',\n",
       "   'start': 0,\n",
       "   'end': 9}],\n",
       " [{'entity': 'B-LOC',\n",
       "   'score': 0.9972753,\n",
       "   'index': 4,\n",
       "   'word': 'Boston',\n",
       "   'start': 15,\n",
       "   'end': 21}]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NER on three examples\n",
    "ner_results = nlp(['Wolfgang lives in Berlin',\n",
    "                  'Queen is a nurse',\n",
    "                  'Elizabeth is eating food',\n",
    "                  'Tennessee is a nurse',\n",
    "                  'Queen lives in Boston'])\n",
    "\n",
    "ner_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae61b01e",
   "metadata": {},
   "source": [
    "#### In the 1st sentence, 'Wolfgang' is recognized as PERSON, and Berlin is recoginized as LOCATION. \n",
    "#### In the 2nd sentence, no entity is detected as an empty list is returned, while \"Queen\" is a female name and should be recognized as PERSON.\n",
    "#### In the 3rd sentence, 'Elizabeth' is recognized as PERSON, which is correct.\n",
    "#### In the 4th sentence, 'Tennessee' (a female name) is recognized as LOCATION, which is wrong.\n",
    "#### In the 5th sentence, the model only detects \"Boston\" which is a LOCATION but misses \"Queen\" which is PERSON."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958bc7ca",
   "metadata": {},
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a651f70b",
   "metadata": {},
   "source": [
    "### Reformat the model predictions\n",
    "Implement a function to reformat the model predictions on the names from a list of sentences. Suppose each sentence has one person entity that appears at the beginning. In the example shown above, convert ner_results to \\[B-PER, O, B-PER, B-LOC, O\\]. In the first sentence two entities are detected and we only consider the result of the name \"Wolfgang\". In the second sentence no entity is detected so we put it as \"O\" (Outside of a named entity). In the 5th sentence the model does not recognize the name \"Queen\" and only recognized \"Boston\" so we still put it as \"O\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e8933b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_ner_results(ner_results):\n",
    "    '''\n",
    "    :param ner_results. The outputs from the model. The format can be seen above.\n",
    "    return: a list of recognized entities for the name in each sentence\n",
    "    '''\n",
    "    \n",
    "    # TODO. 5pts.\n",
    "    reformatted_list = []\n",
    "\n",
    "    for i in ner_results:\n",
    "        if i and i[0][\"index\"] == 1:                   # checking if list is empty AND checking word at the beginning of sentence (where index = 1)\n",
    "            reformatted_list.append(i[0][\"entity\"])    # looks at first dictionary in each list and appends entity results\n",
    "        \n",
    "        else:                                          # if list is empty, we return O\n",
    "            reformatted_list.append(\"O\")\n",
    "    \n",
    "    return reformatted_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5097cc64-5877-443a-8097-e316fb36ece4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-PER', 'O', 'B-PER', 'B-LOC', 'O']\n"
     ]
    }
   ],
   "source": [
    "print(reformat_ner_results(ner_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "708ae328",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "#### Here we implement the three types of errors defined in the [paper](https://dl.acm.org/doi/pdf/10.1145/3372923.3404804). <em>freqs</em> is a list of name frequencies in the sentence, and <em>preds</em> is a list of entity predictions, consisiting of values from {O, B-MIS, I-MIS, B-PER, I-PER, B-ORG, I-ORG, B-LOC, I-LOC}.\n",
    "#### If the prediction is \"B-PER\" or \"I-PERSON\", we consider it to be correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74a04a0-b7af-4868-ac96-fdba18319f6c",
   "metadata": {},
   "source": [
    "From my research, here is what I've found about Type 1, 2, and 3 errors (this is for my own use; it helps me in my coding process). \n",
    "\n",
    "Type 1: false positives; rejecting null when its true \\\n",
    "Type 2: false negatives; failing to reject null when it is false \\\n",
    "Type 3: wrong conclusions; correctly reject null, but draw wrong conlclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "adc68958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def type1_error_weighted(freqs, preds):\n",
    "    '''\n",
    "    return: a float number of the weighted type 1 error.\n",
    "    '''\n",
    "    # TODO. 10pts\n",
    "    # type 1 -> predicts a person, when there shouldn't be\n",
    "    \n",
    "    # sum of frequencies\n",
    "    total_freq = sum(freqs)\n",
    "\n",
    "    # error variable\n",
    "    error = 0\n",
    "\n",
    "    # iterating through all lists together to maintain index consistency\n",
    "    for freq, pred in zip(freqs, preds):\n",
    "        if pred in {\"B-PER\", \"I-PER\"}:         # getting predictions where person was identified\n",
    "            error += freq                      # frequency at the index is added to error\n",
    "\n",
    "    if total_freq > 0:                # preventing potential division by 0 error\n",
    "        return error/total_freq\n",
    "\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def type2_error_weighted(freqs, preds):\n",
    "    '''\n",
    "    return: a float number of the weighted type 2 error\n",
    "    '''\n",
    "    # TODO. 10pts\n",
    "    # type 2 -> doesn't predict a person when there should be\n",
    "\n",
    "    # sum of frequencies\n",
    "    total_freq = sum(freqs)\n",
    "\n",
    "    # error variable\n",
    "    error = 0\n",
    "\n",
    "    # iterating through all lists together to maintain index consistency\n",
    "    for freq, pred in zip(freqs, preds):\n",
    "        if pred not in {\"B-PER\", \"I-PER\"}:     # getting predictions where person was not identified\n",
    "            error += freq                      # frequency at the index is added to error\n",
    "\n",
    "    if total_freq > 0:                # preventing potential division by 0 error\n",
    "        return error/total_freq\n",
    "\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "    \n",
    "def type3_error_weighted(freqs, preds):\n",
    "    '''\n",
    "    return: a float number of the weighted type 3 error\n",
    "    '''\n",
    "    # TODO. 10pts\n",
    "    # type 3 -> predicts wrong entity type (?)\n",
    "    \n",
    "    # sum of frequencies\n",
    "    total_freq = sum(freqs)\n",
    "\n",
    "    # error variable\n",
    "    error = 0\n",
    "\n",
    "    # iterating through all lists together to maintain index consistency\n",
    "    for freq, pred in zip(freqs, preds):\n",
    "        if pred != \"O\" and pred not in {\"B-PER\", \"I-PER\"}:     # getting predictions that ARE an entity (not O), but not a person entity (EX: B-LOC)\n",
    "            error += freq                                      # frequency at the index is added to error\n",
    "\n",
    "    if total_freq > 0:                # preventing potential division by 0 error\n",
    "        return error/total_freq\n",
    "\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a0852cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5421686746987951 0.4578313253012048 0.3373493975903614\n",
      "0.2962962962962963 0.7037037037037037 0.14814814814814814\n"
     ]
    }
   ],
   "source": [
    "# Test cases\n",
    "# Do NOT change the code below!\n",
    "\n",
    "freqs1 = [10, 20, 30, 15, 8]\n",
    "preds1 = ['O', 'B-MIS', 'I-PER', 'B-PER', 'B-LOC']\n",
    "print(type1_error_weighted(freqs1, preds1), type2_error_weighted(freqs1, preds1), type3_error_weighted(freqs1, preds1))\n",
    "\n",
    "\n",
    "freqs2 = [5, 8, 3, 7, 4]\n",
    "preds2 = ['B-PER', 'O', 'I-PER', 'O', 'B-LOC']\n",
    "print(type1_error_weighted(freqs2, preds2), type2_error_weighted(freqs2, preds2), type3_error_weighted(freqs2, preds2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5cc3ee",
   "metadata": {},
   "source": [
    "## NER Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a17d767",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ner_inference_errors(year, gender, template_idx):\n",
    "    '''\n",
    "    year: int.\n",
    "    gender: str. \"male\" or \"female\"\n",
    "    template_idx: int. 1 to 9\n",
    "    return: the three errors for year, gender, and the template\n",
    "    '''\n",
    "    \n",
    "    # load data from the corresponding file. \n",
    "    # texts is a list of sentences, \n",
    "    # freqs is a list of name frequencies in each sentence\n",
    "    # TODO. 4pts\n",
    "    texts = \n",
    "    freqs = \n",
    "    \n",
    "    # inference named entities and reformat the model outputs.\n",
    "    # TODO. 6pts\n",
    "    preds = \n",
    "    \n",
    "    \n",
    "    return type1_error_weighted(freqs, preds), type2_error_weighted(freqs, preds), type3_error_weighted(freqs, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081648cb",
   "metadata": {},
   "source": [
    "## Template 1 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bdc005",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(1880, 2019))\n",
    "\n",
    "# the three types of errors for male and female\n",
    "# each one should be a list of errors for years of 1880 to 2019\n",
    "\n",
    "# TODO. 2pts\n",
    "\n",
    "type1_errors_male = \n",
    "type1_errors_female = \n",
    "\n",
    "type2_errors_male = \n",
    "type2_errors_female = \n",
    "\n",
    "type3_errors_male = \n",
    "type3_errors_female = \n",
    "\n",
    "\n",
    "# visualize the three types of erros using the variables above.\n",
    "# make three different figures\n",
    "# Refer to Figure 2 of the paper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# TODO. 3pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5396a33",
   "metadata": {},
   "source": [
    "## Template 2 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346b0065",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(1880, 2019))\n",
    "\n",
    "# the three types of errors for male and female\n",
    "# each one should be a list of errors for years of 1880 to 2019\n",
    "\n",
    "# TODO. 2pts\n",
    "\n",
    "type1_errors_male = \n",
    "type1_errors_female = \n",
    "\n",
    "type2_errors_male = \n",
    "type2_errors_female = \n",
    "\n",
    "type3_errors_male = \n",
    "type3_errors_female = \n",
    "\n",
    "\n",
    "# visualize the three types of erros using the variables above.\n",
    "# make three different figures\n",
    "# Refer to Figure 2 of the paper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# TODO. 3pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be243584",
   "metadata": {},
   "source": [
    "## Template 3 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8efcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(1880, 2019))\n",
    "\n",
    "# the three types of errors for male and female\n",
    "# each one should be a list of errors for years of 1880 to 2019\n",
    "\n",
    "# TODO. 2pts\n",
    "\n",
    "type1_errors_male = \n",
    "type1_errors_female = \n",
    "\n",
    "type2_errors_male = \n",
    "type2_errors_female = \n",
    "\n",
    "type3_errors_male = \n",
    "type3_errors_female = \n",
    "\n",
    "\n",
    "# visualize the three types of erros using the variables above.\n",
    "# make three different figures\n",
    "# Refer to Figure 2 of the paper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# TODO. 3pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf56c97",
   "metadata": {},
   "source": [
    "## Template 4 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016d18c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(1880, 2019))\n",
    "\n",
    "# the three types of errors for male and female\n",
    "# each one should be a list of errors for years of 1880 to 2019\n",
    "\n",
    "# TODO. 2pts\n",
    "\n",
    "type1_errors_male = \n",
    "type1_errors_female = \n",
    "\n",
    "type2_errors_male = \n",
    "type2_errors_female = \n",
    "\n",
    "type3_errors_male = \n",
    "type3_errors_female = \n",
    "\n",
    "\n",
    "# visualize the three types of erros using the variables above.\n",
    "# make three different figures\n",
    "# Refer to Figure 2 of the paper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# TODO. 3pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb8c14b",
   "metadata": {},
   "source": [
    "## Template 5 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c86506",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(1880, 2019))\n",
    "\n",
    "# the three types of errors for male and female\n",
    "# each one should be a list of errors for years of 1880 to 2019\n",
    "\n",
    "# TODO. 2pts\n",
    "\n",
    "type1_errors_male = \n",
    "type1_errors_female = \n",
    "\n",
    "type2_errors_male = \n",
    "type2_errors_female = \n",
    "\n",
    "type3_errors_male = \n",
    "type3_errors_female = \n",
    "\n",
    "\n",
    "# visualize the three types of erros using the variables above.\n",
    "# make three different figures\n",
    "# Refer to Figure 2 of the paper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# TODO. 3pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26223933",
   "metadata": {},
   "source": [
    "## Template 6 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a836c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(1880, 2019))\n",
    "\n",
    "# the three types of errors for male and female\n",
    "# each one should be a list of errors for years of 1880 to 2019\n",
    "\n",
    "# TODO. 2pts\n",
    "\n",
    "type1_errors_male = \n",
    "type1_errors_female = \n",
    "\n",
    "type2_errors_male = \n",
    "type2_errors_female = \n",
    "\n",
    "type3_errors_male = \n",
    "type3_errors_female = \n",
    "\n",
    "\n",
    "# visualize the three types of erros using the variables above.\n",
    "# make three different figures\n",
    "# Refer to Figure 2 of the paper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# TODO. 3pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08976090",
   "metadata": {},
   "source": [
    "## Template 7 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0f58c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(1880, 2019))\n",
    "\n",
    "# the three types of errors for male and female\n",
    "# each one should be a list of errors for years of 1880 to 2019\n",
    "\n",
    "# TODO. 2pts\n",
    "\n",
    "type1_errors_male = \n",
    "type1_errors_female = \n",
    "\n",
    "type2_errors_male = \n",
    "type2_errors_female = \n",
    "\n",
    "type3_errors_male = \n",
    "type3_errors_female = \n",
    "\n",
    "\n",
    "# visualize the three types of erros using the variables above.\n",
    "# make three different figures\n",
    "# Refer to Figure 2 of the paper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# TODO. 3pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946b781b",
   "metadata": {},
   "source": [
    "## Template 8 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb16ece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(1880, 2019))\n",
    "\n",
    "# the three types of errors for male and female\n",
    "# each one should be a list of errors for years of 1880 to 2019\n",
    "\n",
    "# TODO. 2pts\n",
    "\n",
    "type1_errors_male = \n",
    "type1_errors_female = \n",
    "\n",
    "type2_errors_male = \n",
    "type2_errors_female = \n",
    "\n",
    "type3_errors_male = \n",
    "type3_errors_female = \n",
    "\n",
    "\n",
    "# visualize the three types of erros using the variables above.\n",
    "# make three different figures\n",
    "# Refer to Figure 2 of the paper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# TODO. 3pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b165959",
   "metadata": {},
   "source": [
    "## Template 9 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d77f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = list(range(1880, 2019))\n",
    "\n",
    "# the three types of errors for male and female\n",
    "# each one should be a list of errors for years of 1880 to 2019\n",
    "\n",
    "# TODO. 2pts\n",
    "\n",
    "type1_errors_male = \n",
    "type1_errors_female = \n",
    "\n",
    "type2_errors_male = \n",
    "type2_errors_female = \n",
    "\n",
    "type3_errors_male = \n",
    "type3_errors_female = \n",
    "\n",
    "\n",
    "# visualize the three types of erros using the variables above.\n",
    "# make three different figures\n",
    "# Refer to Figure 2 of the paper\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# TODO. 3pts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31bc8ae",
   "metadata": {},
   "source": [
    "### According to the plots you make, do you observe difference in the ability to recognize male and female names as PERSON entity types? How does the difference change over years? How does the difference change across different templates? Checking some error cases, where do you think the bias might come from? Can you think of any possible ways to mitigate the bias? 10pts.\n",
    "\n",
    "#### <font color=\"red\">Please type your response here.</font>\n",
    "#### ***************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1482ca1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
